{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anous\\AppData\\Local\\Temp\\ipykernel_4328\\2532888164.py:4: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  groundwater_quality_data = groundwater_quality_data.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
      "C:\\Users\\anous\\AppData\\Local\\Temp\\ipykernel_4328\\2532888164.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  sdp_data = sdp_data.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
      "C:\\Users\\anous\\AppData\\Local\\Temp\\ipykernel_4328\\2532888164.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  gini_index_data = gini_index_data.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "groundwater_quality_data = pd.read_csv(\"Copy of District-Level_GWQ_AllYears.csv\")\n",
    "sdp_data = pd.read_csv(\"sdp_data.csv\")\n",
    "gini_index_data = pd.read_csv(\"gini.csv\")\n",
    "groundwater_quality_data = groundwater_quality_data.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "sdp_data = sdp_data.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "gini_index_data = gini_index_data.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "merged_data = pd.merge(groundwater_quality_data, sdp_data, on=['state', 'year'], how='inner')\n",
    "\n",
    "merged_data = pd.merge(merged_data, gini_index_data, on='district', how='inner')\n",
    "\n",
    "merged_data.to_csv(\"merged_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(\"merged_data.csv\")\n",
    "merged_data[\"SDP_sq\"]=merged_data[\"SDP_NORM\"]**2\n",
    "merged_data[\"SDP_cube\"]=merged_data[\"SDP_NORM\"]**3\n",
    "merged_data.to_csv(\"merged_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(\"merged_data.csv\")\n",
    "north_states = ['CHANDIGARH', 'DELHI', 'HARYANA', 'HIMACHAL PRADESH', 'JAMMU & KASHMIR', 'PUNJAB', 'RAJASTHAN']\n",
    "merged_data['north'] = merged_data['state'].apply(lambda x: 1 if x in north_states else None)\n",
    "\n",
    "ne_states = ['ARUNACHAL PRADESH', 'ASSAM', 'MANIPUR', 'MEGHALAYA', 'MIZORAM', 'NAGALAND', 'TRIPURA']\n",
    "merged_data['northeast'] = merged_data['state'].apply(lambda x: 1 if x in ne_states else None)\n",
    "\n",
    "east_states = ['ANDAMAN & NICOBAR ISLANDS', 'BIHAR', 'JHARKHAND', 'ORISSA', 'SIKKIM', 'WEST BENGAL']\n",
    "merged_data['east'] = merged_data['state'].apply(lambda x: 1 if x in east_states else None)\n",
    "\n",
    "central_states = ['CHHATTISGARH', 'MADHYA PRADESH', 'UTTAR PRADESH', 'UTTARAKHAND']\n",
    "merged_data['central'] = merged_data['state'].apply(lambda x: 1 if x in central_states else None)\n",
    "\n",
    "west_states = ['THE DADRA AND NAGAR HAVELI AND DAMAN AND DIU', 'GOA', 'GUJARAT', 'MAHARASHTRA']\n",
    "merged_data['west'] = merged_data['state'].apply(lambda x: 1 if x in west_states else None)\n",
    "\n",
    "south_states = ['ANDHRA PRADESH', 'KARNATAKA', 'KERALA', 'LAKSHADWEEP', 'PONDICHERRY', 'TAMIL NADU','TELANGANA']\n",
    "merged_data['south'] = merged_data['state'].apply(lambda x: 1 if x in south_states else None)\n",
    "\n",
    "merged_data.to_csv(\"regionwise_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(\"merged_data.csv\")\n",
    "merged_data['2000'] = merged_data['year'].apply(lambda x: 1 if x ==2000 else None)\n",
    "merged_data['2001'] = merged_data['year'].apply(lambda x: 1 if x ==2001 else None)\n",
    "merged_data['2002'] = merged_data['year'].apply(lambda x: 1 if x ==2002 else None)\n",
    "merged_data['2003'] = merged_data['year'].apply(lambda x: 1 if x ==2003 else None)\n",
    "merged_data['2004'] = merged_data['year'].apply(lambda x: 1 if x ==2004 else None)\n",
    "merged_data['2005'] = merged_data['year'].apply(lambda x: 1 if x ==2005 else None)\n",
    "merged_data['2006'] = merged_data['year'].apply(lambda x: 1 if x ==2006 else None)\n",
    "merged_data['2007'] = merged_data['year'].apply(lambda x: 1 if x ==2007 else None)\n",
    "merged_data['2008'] = merged_data['year'].apply(lambda x: 1 if x ==2008 else None)\n",
    "merged_data['2009'] = merged_data['year'].apply(lambda x: 1 if x ==2009 else None)\n",
    "merged_data['2010'] = merged_data['year'].apply(lambda x: 1 if x ==2010 else None)\n",
    "merged_data['2011'] = merged_data['year'].apply(lambda x: 1 if x ==2011 else None)\n",
    "merged_data['2012'] = merged_data['year'].apply(lambda x: 1 if x ==2012 else None)\n",
    "merged_data['2013'] = merged_data['year'].apply(lambda x: 1 if x ==2013 else None)\n",
    "merged_data['2014'] = merged_data['year'].apply(lambda x: 1 if x ==2014 else None)\n",
    "merged_data['2015'] = merged_data['year'].apply(lambda x: 1 if x ==2015 else None)\n",
    "merged_data['2016'] = merged_data['year'].apply(lambda x: 1 if x ==2016 else None)\n",
    "merged_data['2017'] = merged_data['year'].apply(lambda x: 1 if x ==2017 else None)\n",
    "merged_data['2018'] = merged_data['year'].apply(lambda x: 1 if x ==2018 else None)\n",
    "merged_data['2019'] = merged_data['year'].apply(lambda x: 1 if x ==2019 else None)\n",
    "merged_data['2020'] = merged_data['year'].apply(lambda x: 1 if x ==2020 else None)\n",
    "\n",
    "merged_data.to_csv(\"yearwise_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              year    ginivalue       SDP_NORM      sulfate          state  \\\n",
      "count   9713.00000  9531.000000    9681.000000  5496.000000           9713   \n",
      "unique         NaN          NaN            NaN          NaN             30   \n",
      "top            NaN          NaN            NaN          NaN  UTTAR PRADESH   \n",
      "freq           NaN          NaN            NaN          NaN           1397   \n",
      "mean    2008.95923     0.269255  362246.578904    98.163389            NaN   \n",
      "\n",
      "        district  \n",
      "count       9713  \n",
      "unique       494  \n",
      "top     BILASPUR  \n",
      "freq          38  \n",
      "mean         NaN  \n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.read_csv(\"merged_data.csv\")\n",
    "summary_stats = merged_data.describe(include='all')\n",
    "summary_stats_selected = summary_stats.loc[:, ['year', 'ginivalue', 'SDP_NORM', 'sulfate','state','district']]\n",
    "print(summary_stats_selected.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
